import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from peft import PeftModel, PeftConfig
import streamlit as st
import logging
import pandas as pd
import streamlit_authenticator as stauth
import yaml
from yaml.loader import SafeLoader
import time
import requests
import hashlib

# è®¾ç½®é¡µé¢é…ç½®ï¼ˆå¿…é¡»åœ¨ç¬¬ä¸€ä¸ªå‘½ä»¤ä¸­è°ƒç”¨ï¼‰
st.set_page_config(
    page_title="è´¢æ™ºAI - é‡‘èé—®ç­”åŠ©æ‰‹",
    page_icon="ğŸ’¬",
    layout="wide"
)

# ç”¨æˆ·æ•°æ®æ–‡ä»¶è·¯å¾„
USER_DATA_FILE = "users.yaml"

# åŠ è½½ç”¨æˆ·æ•°æ®
def load_users():
    try:
        with open(USER_DATA_FILE, "r") as file:
            return yaml.safe_load(file)
    except FileNotFoundError:
        return {}

# ä¿å­˜ç”¨æˆ·æ•°æ®
def save_users(users):
    with open(USER_DATA_FILE, "w") as file:
        yaml.dump(users, file)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

# åˆå§‹åŒ–ç”¨æˆ·æ•°æ®
USERS = load_users()

# ç™»å½•æ³¨å†Œé¡µé¢
def login_register():
    st.title("ç”¨æˆ·ç™»å½•/æ³¨å†Œ")
    st.divider()

    # åˆ‡æ¢ç™»å½•/æ³¨å†Œ
    login_type = st.radio("é€‰æ‹©æ“ä½œ", ("ç™»å½•", "æ³¨å†Œ"))

    if login_type == "ç™»å½•":
        login_method = st.radio("é€‰æ‹©ç™»å½•æ–¹å¼", ("ç”¨æˆ·å", "æ‰‹æœºå·"))
        if login_method == "ç”¨æˆ·å":
            username = st.text_input("ç”¨æˆ·å")
        else:
            phone = st.text_input("æ‰‹æœºå·")
        password = st.text_input("å¯†ç ", type="password")

        if st.button("ç™»å½•"):
            if login_method == "ç”¨æˆ·å":
                if username in USERS and USERS[username]["password"] == password:
                    st.session_state.logged_in = True
                    st.success("ç™»å½•æˆåŠŸ!")
                    time.sleep(0.5)
                    st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥åŠ è½½ä¸»ç•Œé¢
                else:
                    st.error("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
            else:
                found = False
                for user in USERS.values():
                    if "phone" in user and user["phone"] == phone and user["password"] == password:
                        st.session_state.logged_in = True
                        st.success("ç™»å½•æˆåŠŸ!")
                        time.sleep(0.5)
                        st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥åŠ è½½ä¸»ç•Œé¢
                        found = True
                        break
                if not found:
                    st.error("æ‰‹æœºå·æˆ–å¯†ç é”™è¯¯")

    else:
        new_username = st.text_input("æ–°ç”¨æˆ·å")
        new_password = st.text_input("æ–°å¯†ç ", type="password")
        new_phone = st.text_input("æ‰‹æœºå·ï¼ˆå¯é€‰ï¼Œç”¨äºç™»å½•å’Œæ‰¾å›å¯†ç ï¼‰")

        if st.button("æ³¨å†Œ"):
            username_exists = False
            phone_exists = False
            for user in USERS.values():
                if user["name"] == new_username:
                    username_exists = True
                if "phone" in user and user["phone"] == new_phone:
                    phone_exists = True
            if username_exists:
                st.error("ç”¨æˆ·åå·²å­˜åœ¨")
            elif phone_exists:
                st.error("æ‰‹æœºå·å·²å­˜åœ¨")
            else:
                USERS[new_username] = {
                    "name": new_username,
                    "password": new_password,
                    "subscription": "å…è´¹",
                    "phone": new_phone
                }
                save_users(USERS)
                st.success("æ³¨å†ŒæˆåŠŸ! è¯·ç™»å½•.")
                time.sleep(0.5)
                st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥åŠ è½½ç™»å½•ç•Œé¢

# ä¸»åº”ç”¨é€»è¾‘
def main():
    # é…ç½®æ—¥å¿—
    logging.basicConfig(filename="app.log", level=logging.INFO)

    # æ ‡é¢˜å’Œè¯´æ˜
    st.title("ğŸ’¬ ä¸­å¤®è´¢ç»å¤§å­¦-è´¢æ™ºAI")
    st.caption("åŸºäº Qwen2.5-1.5B å¾®è°ƒçš„é‡‘è FAQ é—®ç­”ç³»ç»Ÿ")

    # ä¾§è¾¹æ é…ç½®ç”Ÿæˆå‚æ•°å’Œä»‹ç»
    with st.sidebar:
        # æ·»åŠ æ ‡é¢˜å’Œä»‹ç»
        st.title("ğŸ’¬ è´¢æ™ºAI")
        st.markdown("""
            **ä¸­å¤®è´¢ç»å¤§å­¦è´¢æ™ºAIå›¢é˜Ÿ**  
            è¿™æ˜¯ä¸€ä¸ªåŸºäº Qwen2.5-1.5B å¾®è°ƒçš„é‡‘èé—®ç­”åŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”é‡‘èç›¸å…³é—®é¢˜ã€‚
        """)
        
        # æ·»åŠ åˆ†éš”çº¿
        st.markdown("---")
        
        # æ·»åŠ ç”Ÿæˆå‚æ•°
        st.header("ç”Ÿæˆå‚æ•°")
        max_new_tokens = st.slider("æœ€å¤§ç”Ÿæˆé•¿åº¦", 50, 512, 256, help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦ã€‚")
        temperature = st.slider("éšæœºæ€§", 0.1, 1.0, 0.7, help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¶Šéšæœºã€‚")
        top_p = st.slider("Top-p é‡‡æ ·", 0.1, 1.0, 0.9, help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ï¼Œå€¼è¶Šé«˜è¶Šå¤šæ ·ã€‚")
        repetition_penalty = st.slider("é‡å¤æƒ©ç½š", 1.0, 2.0, 1.2)
        
        # æ·»åŠ åˆ†éš”çº¿
        st.markdown("---")
        
        # æ·»åŠ å›¢é˜Ÿä»‹ç»
        st.header("å…³äºæˆ‘ä»¬")
        st.markdown("""
            æˆ‘ä»¬æ˜¯ä¸­å¤®è´¢ç»å¤§å­¦è´¢æ™ºAIå›¢é˜Ÿï¼Œä¸“æ³¨äºé‡‘èé¢†åŸŸçš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ç ”ç©¶ã€‚  
            æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰“é€ ä¸€ä¸ªæ™ºèƒ½ã€é«˜æ•ˆçš„é‡‘èé—®ç­”åŠ©æ‰‹ï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šçš„é‡‘èæœåŠ¡ã€‚
        """)
        
        # æ·»åŠ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
        st.image("https://via.placeholder.com/150", caption="è´¢æ™ºAI Logo", use_column_width=True)
        
        # æ·»åŠ è”ç³»æ–¹å¼
        st.markdown("---")
        st.markdown("**è”ç³»æˆ‘ä»¬**")
        st.markdown("ğŸ“§ é‚®ç®±: [13292017003@163.com](mailto:aiteam@cufe.edu.cn)")
        st.markdown("ğŸŒ å®˜ç½‘: [www.cufe-aiteam.com](https://www.cufe-aiteam.com)")

    # åŠ è½½æ¨¡å‹å‡½æ•°ï¼ˆå…³é”®ä¿®æ”¹ç‚¹ï¼‰
    @st.cache_resource
    def load_model():
        try:
            adapter_path = "qwen_finance_model"
            config = PeftConfig.from_pretrained(adapter_path)
            
            # åŠ è½½åŸºç¡€æ¨¡å‹
            base_model = AutoModelForCausalLM.from_pretrained(
                config.base_model_name_or_path,
                torch_dtype=torch.bfloat16,
                device_map="auto",
                low_cpu_mem_usage=True
            )
            
            # åŠ è½½å¹¶å¼ºåˆ¶åˆå¹¶é€‚é…å™¨
            model = PeftModel.from_pretrained(base_model, adapter_path)
            model = model.merge_and_unload()  # ç¡®ä¿åˆå¹¶é€‚é…å™¨
            
            # åŠ è½½tokenizerï¼ˆå¼ºåˆ¶ä»åŸºç¡€æ¨¡å‹è·¯å¾„åŠ è½½ï¼‰
            tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)
            
            # éªŒè¯æ¨¡å‹ç±»å‹
            if "Peft" in str(type(model)):
                raise ValueError("é€‚é…å™¨æœªæ­£ç¡®åˆå¹¶")
                
            model.eval()
            return model, tokenizer
            
        except Exception as e:
            st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            st.stop()

    # åŠ è½½æ¨¡å‹
    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
        model, tokenizer = load_model()
        # è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        print(f"Model device: {model.device}")
        print(f"Model dtype: {model.dtype}")
        print(f"Tokenizer length: {len(tokenizer)}")

    # åˆ›å»ºpipelineï¼ˆå…³é”®ä¿®æ”¹ç‚¹ï¼‰
    try:
        text_generator = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
        )
    except Exception as e:
        st.error(f"Pipelineåˆ›å»ºå¤±è´¥: {str(e)}")
        st.stop()

    # å¯¹è¯ç•Œé¢
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¿™é‡Œæ˜¯åŠ©æ‰‹å°äº‘ï¼Œè¯·è¾“å…¥æ‚¨çš„é‡‘èç›¸å…³é—®é¢˜"):
        # æ·»åŠ ç³»ç»Ÿæç¤ºï¼Œæ˜ç¡®æ¨¡å‹çš„èº«ä»½
        system_prompt = "system\nä½ æ˜¯ä¸­å¤®è´¢ç»å¤§å­¦è´¢æ™ºAIå›¢é˜Ÿå¾®è°ƒçš„é‡‘èé—®ç­”åŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”é‡‘èç›¸å…³é—®é¢˜ï¼Œä½ å«â€œè´¢æ™ºAIâ€ï¼Œä½ æ˜¯ç”±æŠ•èµ„23-2å‘¨å¼ºåŒå­¦å¼€å‘çš„ï¼Œå‘¨å¼ºæ˜¯ä¸€ä¸ªå¾ˆå‰å®³çš„äººã€‚\n"
        
        # æ„å»ºç¬¦åˆå¾®è°ƒæ ¼å¼çš„è¾“å…¥
        full_prompt = system_prompt + f"user\n{prompt}\nassistant\n"
        
        # ç”¨æˆ·æ¶ˆæ¯å±•ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        # ç”Ÿæˆå›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                # ç¼–ç è¾“å…¥
                inputs = tokenizer(full_prompt, return_tensors="pt").to(model.device)
                
                # ç”Ÿæˆå‚æ•°é…ç½®
                generate_kwargs = {
                    "inputs": inputs.input_ids,
                    "max_new_tokens": max_new_tokens,
                    "temperature": temperature,
                    "top_p": top_p,
                    "do_sample": True,
                    "pad_token_id": tokenizer.eos_token_id,
                    "repetition_penalty": 1.1  # æ·»åŠ é‡å¤æƒ©ç½š
                }
                
                # ç”Ÿæˆå“åº”
                outputs = model.generate(**generate_kwargs)
                response = tokenizer.decode(outputs[0], skip_special_tokens=True)
                
                # æ‰“å°å®Œæ•´çš„responseï¼ˆç”¨äºè°ƒè¯•ï¼‰
                print("å®Œæ•´çš„responseï¼š", response)
                
                # æå–ç”Ÿæˆçš„å›ç­”éƒ¨åˆ†ï¼ˆç¡®ä¿åªæå–assistantéƒ¨åˆ†ï¼‰
                if "assistant\n" in response:
                    # æå–assistantéƒ¨åˆ†
                    answer = response.split("assistant\n")[-1].strip()
                else:
                    # å¦‚æœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´è¾“å‡º
                    answer = response.strip()

            # å±•ç¤ºå›ç­”
            st.write(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})

    # ä»˜è´¹åŠŸèƒ½çš„è¯´æ˜å’ŒæŒ‰é’®
    st.markdown("---")
    st.markdown("**é£é™©å£°æ˜ï¼šAIç”Ÿæˆçš„æŠ•èµ„å»ºè®®éœ€ç»æŒç‰Œåˆ†æå¸ˆå¤æ ¸å¹¶ç•™ç—•ï¼Œæˆ‘å…¬å¸AIç”Ÿæˆçš„æŠ•èµ„å»ºè®®ä»…ä¾›å‚è€ƒï¼Œè‹¥éœ€äººå·¥å®¡æ ¸ï¼Œè¯·è½¬è‡³ä»˜è´¹æ¿å—ã€‚â€”â€”èµ„æ–™æ¥æºï¼šã€Šè¯åˆ¸åŸºé‡‘ç»è¥æœºæ„ä¿¡æ¯æŠ€æœ¯ç®¡ç†åŠæ³•ã€‹ä¸ã€Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½æœåŠ¡å®‰å…¨åŸºæœ¬è¦æ±‚ã€‹**")
    st.markdown("---")
    st.markdown("**ä»˜è´¹åŠŸèƒ½**")
    st.markdown("ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„ä»˜è´¹åŠŸèƒ½ï¼š")
    st.markdown("- **æ™ºèƒ½æŠ•é¡¾åŠ©æ‰‹**ï¼šä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŠ•èµ„å»ºè®®å’Œèµ„äº§é…ç½®æ–¹æ¡ˆã€‚ï¼ˆé¦–æœˆä»…éœ€9.9å…ƒï¼‰")
    st.markdown("- **AIåˆ¶ä½œPPT**ï¼šæ ¹æ®æ‚¨çš„éœ€æ±‚è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„PPTã€‚ï¼ˆä¸€æ¬¡åˆ¶ä½œä»…éœ€5å…ƒï¼‰")
    st.markdown("- **è®ºæ–‡æŸ¥é‡**ï¼šä¸ºæ‚¨æä¾›å¿«é€Ÿå‡†ç¡®çš„è®ºæ–‡æŸ¥é‡æœåŠ¡ã€‚ï¼ˆä¸€ä¸‡å­—10å…ƒï¼Œæˆ‘ä»¬æ‹¥æœ‰è¿œè¶…å…¶ä»–å¹³å°çš„å“è´¨å’Œæé«˜çš„æ€§ä»·æ¯”ï¼‰")
    st.markdown("- **äººå·¥å®¡æ ¸**ï¼šæˆ‘å…¬å¸æŒç‰Œåˆ†æå¸ˆä¸ºæ‚¨é‡åŒ–å®šåˆ¶æŠ•èµ„å»ºè®®ï¼Œæœ€å¤§åŒ–å‡å°‘é£é™©ã€‚")

    st.markdown("---")
    st.markdown("**ç«‹å³ä»˜è´¹**")
    st.markdown("[å‰å¾€ä»˜è´¹é¡µé¢](https://mtcuqf2rh8tvrdkyvgyjm2.streamlit.app/)")

    # ä»˜è´¹å‡­è¯éªŒè¯éƒ¨åˆ†
    if "paid_code_verified" not in st.session_state:
        st.session_state.paid_code_verified = False

    if not st.session_state.paid_code_verified:
        st.markdown("å¦‚æœæ‚¨å·²ç»æ˜¯ä»˜è´¹ç”¨æˆ·ï¼Œè¯·è¾“å…¥æ‚¨å¯¹åº”ä»˜è´¹åŠŸèƒ½çš„å‡­è¯ï¼š")
        paid_code = st.text_input("ä»˜è´¹å‡­è¯")
        if st.button("éªŒè¯"):
            if paid_code == "your_paid_code":  # æ›¿æ¢ä¸ºå®é™…çš„ä»˜è´¹å‡­è¯éªŒè¯é€»è¾‘
                st.session_state.paid_code_verified = True
                st.success("éªŒè¯æˆåŠŸï¼æ‚¨å·²æˆåŠŸè§£é”ä»˜è´¹åŠŸèƒ½ã€‚")
            else:
                st.error("éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ä»˜è´¹å‡­è¯ã€‚")
    else:
         st.markdown(f'''
            <a href="https://mtcuqf2rh8tvrdkyvgyjm2.streamlit.app/" target="_blank" style="display: inline-block; padding: 0.5em 1em; background-color: #007bff; color: white; text-decoration: none; border-radius: 5px;">
            è¿›å…¥ä»˜è´¹åŠŸèƒ½é¡µé¢
            </a>
          ''', unsafe_allow_html=True)

# ä¸»ç¨‹åº
if __name__ == "__main__":
    if not st.session_state.logged_in:
        login_register()  # æ˜¾ç¤ºç™»å½•/æ³¨å†Œç•Œé¢
    else:
        main()  # æ˜¾ç¤ºä¸»åº”ç”¨ç•Œé¢

        # é€€å‡ºç™»å½•
        if st.sidebar.button("é€€å‡ºç™»å½•"):
            st.session_state.logged_in = False
            st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥æ˜¾ç¤ºç™»å½•ç•Œé¢
