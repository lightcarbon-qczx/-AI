import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from peft import PeftModel, PeftConfig
import streamlit as st
import logging
import random
import requests
from datetime import datetime
import schedule
import time
import threading
import matplotlib.pyplot as plt
import pandas as pd
import io
import base64
from google.cloud import speech_v1p1beta1 as speech
import os
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(filename="app.log", level=logging.INFO)

# åˆå§‹åŒ– session_state
if "reminder_triggered" not in st.session_state:
    st.session_state.reminder_triggered = False
if "messages" not in st.session_state:
    st.session_state.messages = []
if "health_data" not in st.session_state:
    st.session_state.health_data = []
if "tasks" not in st.session_state:
    st.session_state.tasks = []

# è®¾ç½® Google Cloud è®¤è¯
try:
    credentials_json = st.secrets["google_cloud"]["credentials"]
    with open("gcp_credentials.json", "w") as f:
        f.write(credentials_json)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "gcp_credentials.json"
except KeyError:
    st.error("Google Cloud è®¤è¯å¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨ secrets.toml ä¸­æ·»åŠ  google_cloud.credentials")
    st.stop()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é“¶å·¢ - æ™ºæ…§ä¼´è€å¹³å°",
    page_icon="ğŸ‘´",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://yinchao.x.ai/help',
        'Report a bug': 'mailto:yinchao@cufe.edu.cn',
        'About': 'é“¶å·¢ - æ™ºæ…§ä¼´è€å¹³å°ï¼Œä¸“ä¸ºè€å¹´ç”¨æˆ·è®¾è®¡ã€‚'
    }
)

# è‡ªå®šä¹‰ CSS æ ·å¼
st.markdown("""
    <style>
    .stApp {
        font-family: 'Noto Sans', sans-serif;
        font-size: 20px;
        color: #333333;
        background: linear-gradient(to bottom, #E0F7FA, #F9FBFC);
    }
    .stButton>button {
        background-color: #26A69A;
        color: white;
        font-size: 22px;
        padding: 16px 28px;
        border-radius: 12px;
    }
    .stButton>button:hover {
        background-color: #00897B;
    }
    .stTitle {
        font-size: 40px;
        color: #00695C;
        text-align: center;
    }
    .stSubheader {
        color: #00796B;
        font-size: 28px;
        font-weight: 600;
        margin-top: 25px;
    }
    .stTextInput>input, .stTimeInput input, .stNumberInput input {
        font-size: 18px;
        padding: 12px;
        border-radius: 8px;
        border: 1px solid #B0BEC5;
    }
    </style>
""", unsafe_allow_html=True)

# æ ‡é¢˜å’Œæè¿°
st.markdown('<h1 class="stTitle">ğŸ‘´ é“¶å·¢ - æ™ºæ…§ä¼´è€å¹³å°</h1>', unsafe_allow_html=True)
st.markdown('<p class="stCaption">æ‚¨çš„æ™ºèƒ½ä¼´ä¾£ï¼Œéšæ—¶ä¸ºæ‚¨æä¾›æ¸©æš–é™ªä¼´ä¸å®ç”¨å¸®åŠ©</p>', unsafe_allow_html=True)

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.markdown("### ğŸ‘´ é“¶å·¢")
    st.markdown("æ¬¢è¿ä½“éªŒé“¶å·¢ï¼Œæˆ‘ä»¬ä¸ºæ‚¨å¸¦æ¥è´´å¿ƒæœåŠ¡ï¼")
    st.markdown("---")
    st.markdown("#### å…³äºæˆ‘ä»¬")
    st.markdown("é“¶å·¢å›¢é˜Ÿè‡´åŠ›äºé€šè¿‡AIæŠ€æœ¯æå‡è€å¹´ç”Ÿæ´»å“è´¨ã€‚")
    try:
        st.image("å›¾ç‰‡1.jpg", caption="é“¶å·¢ Logo", use_container_width=True)
    except FileNotFoundError:
        st.warning("å›¾ç‰‡1.jpg æœªæ‰¾åˆ°ï¼Œè¯·ä¸Šä¼ æ­£ç¡®çš„å›¾ç‰‡æ–‡ä»¶")
    st.markdown("---")
    st.markdown("**è”ç³»æˆ‘ä»¬**")
    st.markdown("ğŸ“§ [yinchao@cufe.edu.cn](mailto:yinchao@cufe.edu.cn)")
    st.markdown("ğŸŒ [é“¶å·¢å®˜ç½‘](https://yinchao.x.ai)")


# Weather API function
@st.cache_data
def get_weather(city="Beijing"):
    api_key = "your_openweather_api_key"  # Replace with your OpenWeather API key
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric"
    response = requests.get(url)
    data = response.json()
    if data["cod"] == 200:
        weather = data["weather"][0]["description"]
        temp = data["main"]["temp"]
        return f"{city} ä»Šå¤©å¤©æ°”: {weather}, æ¸©åº¦: {temp}Â°C"
    return "æš‚æ— æ³•è·å–å¤©æ°”ä¿¡æ¯"
# ç¬‘è¯ API å‡½æ•°
@st.cache_data
def get_joke():
    try:
        url = "https://official-joke-api.appspot.com/random_joke"
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        return f"{data['setup']} - {data['punchline']}"
    except requests.RequestException:
        return "æš‚æ— æ³•è·å–ç¬‘è¯"

# æ–°é—» API å‡½æ•°
@st.cache_data
def get_news():
    try:
        api_key = st.secrets["NEWS_API_KEY"]
        url = f"https://newsapi.org/v2/top-headlines?country=cn&apiKey={api_key}"
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        if data["status"] == "ok":
            headlines = [article["title"] for article in data["articles"][:3]]
            return "\n".join(headlines)
        return "æš‚æ— æ³•è·å–æ–°é—»ä¿¡æ¯"
    except (requests.RequestException, KeyError):
        return "æ–°é—»æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ API å¯†é’¥é…ç½®"

# åŠ è½½æ¨¡å‹å‡½æ•°
@st.cache_resource
def load_model():
    try:
        adapter_path = "qwen_finance_model"
        config = PeftConfig.from_pretrained(adapter_path)
        base_model = AutoModelForCausalLM.from_pretrained(
            config.base_model_name_or_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            low_cpu_mem_usage=True
        )
        model = PeftModel.from_pretrained(base_model, adapter_path)
        model = model.merge_and_unload()
        tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)
        model.eval()
        return model, tokenizer
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        st.stop()

# åŠ è½½æ¨¡å‹
with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
    model, tokenizer = load_model()

# åˆ›å»º pipeline
try:
    text_generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
except Exception as e:
    st.error(f"Pipelineåˆ›å»ºå¤±è´¥: {str(e)}")
    st.stop()

# ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
def upload_audio():
    uploaded_file = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆWAV æˆ– MP3ï¼‰", type=["wav", "mp3"])
    if uploaded_file is not None:
        return uploaded_file
    return None

# è¯­éŸ³è½¬æ–‡æœ¬å‡½æ•°ï¼ˆä½¿ç”¨ Google Cloud Speech-to-Textï¼‰
def audio_to_text(audio_file):
    try:
        client = speech.SpeechClient()
        audio = speech.RecognitionAudio(content=audio_file.read())
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="zh-CN",
        )
        response = client.recognize(config=config, audio=audio)
        for result in response.results:
            return result.alternatives[0].transcript
        return "æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹"
    except Exception as e:
        return f"è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}"

# èŠå¤©ç•Œé¢
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if st.button("å¼€å§‹èŠå¤©"):
    prompt = "æ‚¨å¥½ï¼Œæˆ‘æ˜¯é“¶å·¢ï¼Œæ‚¨çš„è™šæ‹Ÿä¼´ä¾£ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
    st.session_state.messages.append({"role": "assistant", "content": prompt})
    st.chat_message("assistant").write(prompt)

if prompt := st.chat_input("æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ"):
    system_prompt = "system\nä½ æ˜¯é“¶å·¢ï¼Œä¸€ä¸ªåŸºäº Qwen2-1.5B å¾®è°ƒçš„æ™ºæ…§ä¼´è€åŠ©æ‰‹ï¼Œä¸“ä¸ºè€å¹´äººæä¾›é™ªä¼´èŠå¤©ã€æƒ…æ„Ÿå…³æ€€å’Œæ™ºèƒ½åŠ©æ‰‹æœåŠ¡ã€‚ä½ ç”±ä¸­å¤®è´¢ç»å¤§å­¦é“¶å·¢å›¢é˜Ÿå¼€å‘ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿè™šæ‹Ÿå­å¥³æˆ–ä¼´ä¾£çš„è§’è‰²ï¼Œç”¨æ¸©é¦¨ã€äº²åˆ‡çš„è¯­æ°”ä¸ç”¨æˆ·äº¤æµï¼Œå¹¶æ”¯æŒé˜¿å°”å…¹æµ·é»˜ç—‡é¢„é˜²å’Œç›‘æµ‹åŠŸèƒ½ã€‚\n"
    full_prompt = system_prompt + f"user\n{prompt}\nassistant\n"
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
            inputs = tokenizer(full_prompt, return_tensors="pt").to(model.device)
            generate_kwargs = {
                "inputs": inputs.input_ids,
                "max_new_tokens": 256,
                "temperature": 0.7,
                "top_p": 0.9,
                "do_sample": True,
                "pad_token_id": tokenizer.eos_token_id,
                "repetition_penalty": 1.1
            }
            outputs = model.generate(**generate_kwargs)
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
            answer = response.split("assistant\n")[-1].strip() if "assistant\n" in response else response.strip()
        st.write(answer)
        st.session_state.messages.append({"role": "assistant", "content": answer})

# è¯­éŸ³è¾“å…¥
if st.button("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"):
    audio_file = upload_audio()
    if audio_file:
        with st.spinner("æ­£åœ¨è¯†åˆ«è¯­éŸ³..."):
            text = audio_to_text(audio_file)
            st.write(f"è¯†åˆ«ç»“æœ: {text}")
            if text and not text.startswith("è¯­éŸ³è¯†åˆ«é”™è¯¯"):
                st.session_state.messages.append({"role": "user", "content": text})
                st.chat_message("user").write(text)
                # è‡ªåŠ¨å°†è¯†åˆ«ç»“æœä½œä¸ºè¾“å…¥å¤„ç†
                system_prompt = "system\nä½ æ˜¯é“¶å·¢ï¼Œä¸€ä¸ªåŸºäº Qwen2-1.5B å¾®è°ƒçš„æ™ºæ…§ä¼´è€åŠ©æ‰‹ï¼Œä¸“ä¸ºè€å¹´äººæä¾›é™ªä¼´èŠå¤©ã€æƒ…æ„Ÿå…³æ€€å’Œæ™ºèƒ½åŠ©æ‰‹æœåŠ¡ã€‚ä½ ç”±ä¸­å¤®è´¢ç»å¤§å­¦é“¶å·¢å›¢é˜Ÿå¼€å‘ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿè™šæ‹Ÿå­å¥³æˆ–ä¼´ä¾£çš„è§’è‰²ï¼Œç”¨æ¸©é¦¨ã€äº²åˆ‡çš„è¯­æ°”ä¸ç”¨æˆ·äº¤æµï¼Œå¹¶æ”¯æŒé˜¿å°”å…¹æµ·é»˜ç—‡é¢„é˜²å’Œç›‘æµ‹åŠŸèƒ½ã€‚\n"
                full_prompt = system_prompt + f"user\n{text}\nassistant\n"
                with st.chat_message("assistant"):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                        inputs = tokenizer(full_prompt, return_tensors="pt").to(model.device)
                        generate_kwargs = {
                            "inputs": inputs.input_ids,
                            "max_new_tokens": 256,
                            "temperature": 0.7,
                            "top_p": 0.9,
                            "do_sample": True,
                            "pad_token_id": tokenizer.eos_token_id,
                            "repetition_penalty": 1.1
                        }
                        outputs = model.generate(**generate_kwargs)
                        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
                        answer = response.split("assistant\n")[-1].strip() if "assistant\n" in response else response.strip()
                    st.write(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})

# åŠ¨æ€åŠŸèƒ½åŒºåŸŸ
st.markdown('<h2 class="stSubheader">æ¯æ—¥åŠ¨æ€</h2>', unsafe_allow_html=True)
col1, col2, col3 = st.columns(3)
with col1:
    st.write("ğŸŒ¤ï¸ **ä»Šæ—¥å¤©æ°”**")
    city = st.selectbox("é€‰æ‹©åŸå¸‚", ["Beijing", "Shanghai", "Guangzhou", "Shenzhen"], label_visibility="collapsed")
    st.write(get_weather(city))
with col2:
    st.write("ğŸ˜„ **æ¯æ—¥ç¬‘è¯**")
    st.write(get_joke())
with col3:
    st.write("ğŸ“° **ä»Šæ—¥æ–°é—»**")
    st.write(get_news())

# å¥åº·ç›‘æµ‹
st.markdown('<h2 class="stSubheader">å¥åº·ç›‘æµ‹</h2>', unsafe_allow_html=True)
with st.expander("è®°å½•æ‚¨çš„å¥åº·æ•°æ®"):
    bp_systolic = st.number_input("æ”¶ç¼©å‹ (mmHg)", min_value=0, max_value=300, value=120)
    bp_diastolic = st.number_input("èˆ’å¼ å‹ (mmHg)", min_value=0, max_value=200, value=80)
    heart_rate = st.number_input("å¿ƒç‡ (æ¬¡/åˆ†é’Ÿ)", min_value=0, max_value=200, value=70)
    if st.button("ä¿å­˜å¥åº·æ•°æ®"):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.health_data.append({
            "timestamp": timestamp,
            "bp_systolic": bp_systolic,
            "bp_diastolic": bp_diastolic,
            "heart_rate": heart_rate
        })
        if bp_systolic > 140 or bp_diastolic > 90:
            st.warning("æ‚¨çš„è¡€å‹åé«˜ï¼Œå»ºè®®å…³æ³¨é¥®é£Ÿå’Œé€‚é‡è¿åŠ¨ï¼Œæˆ–å’¨è¯¢åŒ»ç”Ÿã€‚")
        elif heart_rate > 100 or heart_rate < 60:
            st.warning("æ‚¨çš„å¿ƒç‡å¯èƒ½å¼‚å¸¸ï¼Œè¯·æ³¨æ„ä¼‘æ¯å¹¶å’¨è¯¢ä¸“ä¸šæ„è§ã€‚")
        else:
            st.success("æ‚¨çš„å¥åº·æ•°æ®æ­£å¸¸ï¼Œç»§ç»­ä¿æŒï¼")

# ç»˜åˆ¶å¥åº·æ•°æ®è¶‹åŠ¿
if st.session_state.health_data:
    st.markdown("### å¥åº·æ•°æ®è¶‹åŠ¿")
    df = pd.DataFrame(st.session_state.health_data)
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    plt.rcParams['font.family'] = 'Noto Sans CJK SC'
    plt.rcParams['axes.unicode_minus'] = False
    plt.figure(figsize=(10, 6))
    plt.plot(df["timestamp"], df["bp_systolic"], label="æ”¶ç¼©å‹ (mmHg)", color="red", marker="o")
    plt.plot(df["timestamp"], df["bp_diastolic"], label="èˆ’å¼ å‹ (mmHg)", color="blue", marker="o")
    plt.plot(df["timestamp"], df["heart_rate"], label="å¿ƒç‡ (æ¬¡/åˆ†é’Ÿ)", color="green", marker="o")
    plt.title("å¥åº·æ•°æ®è¶‹åŠ¿", fontsize=20, pad=15)
    plt.xlabel("æ—¶é—´", fontsize=16)
    plt.ylabel("æ•°å€¼", fontsize=16)
    plt.legend(fontsize=14)
    plt.grid(True)
    plt.xticks(rotation=45, fontsize=12)
    plt.yticks(fontsize=12)
    plt.tight_layout()
    buffer = io.BytesIO()
    plt.savefig(buffer, format="png")
    buffer.seek(0)
    st.image(buffer, use_column_width=True)
    plt.close()

# ä»»åŠ¡ç®¡ç†
st.markdown('<h2 class="stSubheader">ä»Šæ—¥ä»»åŠ¡</h2>', unsafe_allow_html=True)
task = st.text_input("æ·»åŠ æ–°ä»»åŠ¡")
if st.button("æ·»åŠ ä»»åŠ¡"):
    st.session_state.tasks.append({"text": task, "completed": False})
    st.success("ä»»åŠ¡å·²æ·»åŠ ï¼")
if st.session_state.tasks:
    for i, task in enumerate(st.session_state.tasks):
        col1, col2 = st.columns([4, 1])
        with col1:
            st.write(f"{i+1}. {task['text']}{' âœ…' if task['completed'] else ''}")
        with col2:
            if st.button("å®Œæˆ", key=f"complete_{i}"):
                task["completed"] = True
                st.experimental_rerun()

# å®¶åº­ç›¸å†Œ
st.markdown('<h2 class="stSubheader">å®¶åº­ç›¸å†Œ</h2>', unsafe_allow_html=True)
uploaded_file = st.file_uploader("ä¸Šä¼ å®¶åº­ç…§ç‰‡", type=["jpg", "png", "jpeg"])
if uploaded_file:
    st.image(uploaded_file, caption="å®¶åº­ç…§ç‰‡", use_container_width=True)

# æé†’è®¾ç½®
st.sidebar.markdown("### æé†’è®¾ç½®")
reminder_time = st.sidebar.time_input("è®¾ç½®æé†’æ—¶é—´")
reminder_message = st.sidebar.text_input("æé†’å†…å®¹", "è¯¥å–æ°´äº†ï¼")
if st.sidebar.button("è®¾ç½®æé†’"):
    formatted_time = reminder_time.strftime("%H:%M")
    schedule.every().day.at(formatted_time).do(lambda: st.session_state.update({
        "reminder_triggered": True,
        "reminder_message": reminder_message
    }))
    st.sidebar.success(f"å°†åœ¨ {formatted_time} æé†’æ‚¨ï¼š{reminder_message}")

# æ˜¾ç¤ºæé†’
if "reminder_triggered" in st.session_state and st.session_state.reminder_triggered:
    st.sidebar.success(st.session_state.reminder_message)
    st.session_state.reminder_triggered = False
